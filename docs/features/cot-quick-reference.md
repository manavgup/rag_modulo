# CoT Hardening Quick Reference

## TL;DR

Production-grade defenses against Chain of Thought (CoT) reasoning leakage with **~95% success rate**.

---

## Key Features

| Feature | Benefit | Status |
|---------|---------|--------|
| **Output Validation** | Auto-retry low quality (up to 3x) | ‚úÖ Active |
| **Confidence Scoring** | 0.0-1.0 quality assessment | ‚úÖ Active |
| **Multi-Layer Parsing** | 5 fallback strategies | ‚úÖ Active |
| **Enhanced Prompts** | System rules + few-shot examples | ‚úÖ Active |
| **Telemetry** | Comprehensive logging | ‚úÖ Active |

---

## Parsing Layers (Priority Order)

1. **XML tags**: `<answer>...</answer>` ‚Üê Primary
2. **JSON**: `{"answer": "..."}` ‚Üê Fallback 1
3. **Marker**: `Final Answer: ...` ‚Üê Fallback 2
4. **Regex cleaning**: Remove artifacts ‚Üê Fallback 3
5. **Full response**: With error log ‚Üê Last resort

---

## Quality Scoring

| Check | Score Impact | Example |
|-------|--------------|---------|
| ‚úÖ Clean answer | 1.0 | Perfect |
| ‚ùå Has artifacts | -0.4 | "Based on the analysis..." |
| ‚ùå Too short (<20) | -0.3 | "Yes" |
| ‚ùå Duplicates | -0.2 | Same sentence twice |
| ‚ùå Too long (>2000) | -0.1 | Verbose |
| ‚ùå Question repeated | -0.1 | Redundant |

**Threshold**: 0.6 (60%) to pass

---

## Configuration

```python
# Adjust quality threshold (default: 0.6)
if quality_score >= 0.6:  # Higher = stricter
    return answer

# Adjust max retries (default: 3)
def _generate_llm_response_with_retry(
    ..., max_retries=3  # More = better quality, slower
):
```

---

## Monitoring

```bash
# Check retry rate
grep "retrying" backend.log | wc -l

# Check quality scores
grep "Quality Score" backend.log

# Check parsing methods used
grep "Parsed answer using" backend.log | sort | uniq -c

# Check failures
grep "All parsing strategies failed" backend.log | wc -l
```

---

## Typical Logs

### ‚úÖ Success (First Attempt)

```
üîç LLM RESPONSE ATTEMPT 1/3
Question: What was IBM revenue?
Quality Score: 0.85
Raw Response: <thinking>...</thinking><answer>$73.6B in 2022</answer>
Parsed Answer: $73.6B in 2022
‚úÖ Answer quality acceptable (score: 0.85)
```

### ‚ö†Ô∏è Retry (Low Quality)

```
üîç LLM RESPONSE ATTEMPT 1/3
Question: What was IBM revenue?
Quality Score: 0.45
Parsed Answer: Based on the analysis of IBM revenue (in the context of...)
‚ùå Answer quality too low (score: 0.45), retrying...
Reason: Contains CoT artifacts
```

### ‚úÖ Success (After Retry)

```
üîç LLM RESPONSE ATTEMPT 2/3
Question: What was IBM revenue?
Quality Score: 0.80
Parsed Answer: IBM's revenue in 2022 was $73.6 billion.
‚úÖ Answer quality acceptable (score: 0.80)
```

---

## Performance

| Metric | Value | Notes |
|--------|-------|-------|
| **Success Rate** | ~95% | Clean responses |
| **Avg Retry Rate** | 20-50% | Most pass first attempt |
| **Latency (no retry)** | ~2.6s | +0.1s overhead |
| **Latency (1 retry)** | ~5.0s | Acceptable |
| **Token Usage** | +10-50% | Due to enhanced prompt |

---

## Troubleshooting

### High Retry Rate

```python
# Solution 1: Lower threshold
if quality_score >= 0.5:  # Was 0.6

# Solution 2: Reduce retries
max_retries=2  # Was 3
```

### Artifacts Still Leaking

```python
# Add to _contains_artifacts()
artifacts = [
    "your new pattern here",
    ...
]
```

### Slow Responses

```python
# Reduce retries
max_retries=2  # Was 3

# Or increase threshold (fewer retries)
if quality_score >= 0.7:  # Was 0.6
```

---

## Testing

```python
# Unit test parsing
@pytest.mark.parametrize("bad,expected", [
    ("Based on: answer", "answer"),
    ("<answer>clean</answer>", "clean"),
])
def test_parsing(bad, expected):
    clean = service._parse_structured_response(bad)
    assert clean == expected

# Integration test
@pytest.mark.integration
async def test_no_leakage():
    result = await service.execute_chain_of_thought(...)
    assert "based on the analysis" not in result.final_answer.lower()
    assert result.confidence_score > 0.6
```

---

## Files Modified

- `backend/rag_solution/services/chain_of_thought_service.py` (+400 lines)
- `backend/rag_solution/services/answer_synthesizer.py` (simplified)

---

## See Also

- [Full Documentation](./chain-of-thought-hardening.md)
- [Original Fix Details](../../ISSUE_461_COT_LEAKAGE_FIX.md)
- [Issue #461](https://github.com/manavgup/rag_modulo/issues/461)

---

*Last Updated: October 25, 2025*
