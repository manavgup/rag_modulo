# =============================================================================
# RAG Modulo Environment Configuration
# =============================================================================
# Copy this file to .env and customize as needed for your environment

# =============================================================================
# CRITICAL: Required for Container Startup
# =============================================================================

# PostgreSQL Database Configuration (Required for backend and MLflow)
COLLECTIONDB_NAME=rag_modulo
COLLECTIONDB_USER=rag_user
COLLECTIONDB_PASS=rag_password

# MinIO Credentials (CRITICAL - Required for Milvus and MLflow)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

# MLflow Tracking Credentials (Required for MLflow server)
MLFLOW_TRACKING_USERNAME=mlflow
MLFLOW_TRACKING_PASSWORD=mlflow123
MLFLOW_PORT=5001

# JWT Configuration (Required for authentication)
JWT_SECRET_KEY=dev-secret-key-change-in-production-f8a7b2c1

# OIDC Configuration (Required for authentication)
OIDC_DISCOVERY_ENDPOINT=http://localhost:8080/.well-known/openid_configuration
OIDC_AUTH_URL=http://localhost:8080/auth
OIDC_TOKEN_URL=http://localhost:8080/token
OIDC_USERINFO_ENDPOINT=http://localhost:8080/userinfo
OIDC_INTROSPECTION_ENDPOINT=http://localhost:8080/introspect
FRONTEND_URL=http://localhost:3000

# IBM WatsonX Credentials (Required for AI services)
IBM_CLIENT_ID=your-ibm-client-id
IBM_CLIENT_SECRET=your-ibm-client-secret
WATSONX_APIKEY=your-watsonx-apikey
WATSONX_URL=https://us-south.ml.cloud.ibm.com
WATSONX_INSTANCE_ID=your-watsonx-instance-id

# Milvus Configuration (Required for vector database)
MILVUS_PORT=19530

# =============================================================================
# DEVELOPMENT SETTINGS (Safe Defaults)
# =============================================================================

# Testing/Development settings
TESTING=true
SKIP_AUTH=true
DEVELOPMENT_MODE=true
MOCK_TOKEN=dev-0000-0000-0000

# Embeddings
EMBEDDING_MODEL=sentence-transformers/all-minilm-l6-v2
EMBEDDING_DIM=384
EMBEDDING_FIELD=embedding  # Name of the field used across vector DBs for embedding purposes
UPSERT_BATCH_SIZE=100 # Unused for now

# WatsonX SDK Embedding Configuration (Rate Limiting & Batching)
EMBEDDING_BATCH_SIZE=5               # Texts per batch (reduced for better rate limiting)
EMBEDDING_CONCURRENCY_LIMIT=1        # Parallel requests (default: 5, max: 10, we use 1 for rate limiting)
EMBEDDING_MAX_RETRIES=10             # Retry attempts (default: 10)
EMBEDDING_DELAY_TIME=1.0             # Exponential backoff factor (increased for better rate limiting)
EMBEDDING_REQUEST_DELAY=0.5          # Delay between embedding requests in seconds (increased for better rate limiting)

# WatsonX SDK LLM Configuration (Rate Limiting & Retry)
LLM_MAX_RETRIES=10                   # Retry attempts for text generation (default: 10)
LLM_DELAY_TIME=0.5                   # Exponential backoff factor for LLM calls (default: 0.5)

# Chunking Strategy
CHUNKING_STRATEGY=fixed # 'fixed' or 'semantic'
MIN_CHUNK_SIZE=100
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=100
SEMANTIC_THRESHOLD=0.5

# Chain of Thought (CoT) Configuration
COT_MAX_REASONING_DEPTH=3  # Maximum number of reasoning steps
COT_REASONING_STRATEGY=decomposition  # 'decomposition', 'iterative', 'hierarchical', 'causal'
COT_TOKEN_BUDGET_MULTIPLIER=2.0  # Token usage multiplier for CoT vs standard search

# Models
TOKENIZER=meta-llama/llama-3-8b
MODEL=google/flan-t5-xl

# Frontend variables
REACT_APP_API_URL=http://localhost:8000

# Vector DB configurations. Modify only the ones you will be using.
CHROMADB_HOST=localhost
CHROMADB_PORT=8000

ELASTIC_HOST=localhost
ELASTIC_PORT=9200
ELASTIC_PASSWORD=elastic-password
ELASTIC_CACERT_PATH=/Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/http_ca.crt
ELASTIC_CLOUD_ID=''
ELASTIC_API_KEY=

PINECONE_API_KEY=pinecone-key
PINECONE_CLOUD=aws # if aws
PINECONE_REGION=us-east-1 # region

MILVUS_HOST=milvus-standalone
MILVUS_PORT=19530
MILVUS_USER=MILVUS_USER
MILVUS_PASSWORD=MILVUS_PASSWORD
MILVUS_INDEX_PARAMS=
MILVUS_SEARCH_PARAMS=

WEAVIATE_HOST=localhost
WEAVIATE_PORT=8080
WEAVIATE_GRPC_PORT=50051
WEAVIATE_USERNAME=username
WEAVIATE_PASSWORD=password
WEAVIATE_INDEX=test_weaviate_index
WEAVIATE_SCOPES=None
PROJECT_NAME=rag_modulo
PYTHON_VERSION=3.11

#Local data directory. For testing purposes only
DATA_DIR=/Users/mg/mg-work/manav/work/ai-experiments/rag_modulo/data

# Container Image Configuration (NEW - for GHCR support)
# Use GHCR images by default (recommended for CI/CD)
BACKEND_IMAGE=ghcr.io/manavgup/rag_modulo/backend:latest
FRONTEND_IMAGE=ghcr.io/manavgup/rag_modulo/frontend:latest
TEST_IMAGE=ghcr.io/manavgup/rag_modulo/backend:latest

# For local development, you can override with local images:
# BACKEND_IMAGE=rag-modulo/backend:1.0.0
# FRONTEND_IMAGE=rag-modulo/frontend:1.0.0
# TEST_IMAGE=rag-modulo/backend-test:1.0.0

# =============================================================================
# CRITICAL: Required Environment Variables for Container Startup
# =============================================================================

# PostgreSQL Database Configuration (Required for backend and MLflow)
COLLECTIONDB_NAME=rag_modulo
COLLECTIONDB_USER=rag_user
COLLECTIONDB_PASS=rag_password

# MinIO Credentials (CRITICAL - Required for Milvus and MLflow)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

# MLflow Tracking Credentials (Required for MLflow server)
MLFLOW_TRACKING_USERNAME=mlflow
MLFLOW_TRACKING_PASSWORD=mlflow123
MLFLOW_PORT=5001

# IBM WatsonX Credentials (Required for AI services)
IBM_CLIENT_ID=your-ibm-client-id
IBM_CLIENT_SECRET=your-ibm-client-secret
WATSONX_APIKEY=your-watsonx-apikey
WATSONX_URL=https://us-south.ml.cloud.ibm.com
WATSONX_INSTANCE_ID=your-watsonx-instance-id

# Milvus Configuration (Required for vector database)
MILVUS_PORT=19530


# =============================================================================
# DEVELOPMENT SETUP INSTRUCTIONS
# =============================================================================
#
# LOCAL DEVELOPMENT:
# 1. Copy this file: cp .env.example .env
# 2. Edit .env and replace placeholder values with your actual credentials
# 3. Start development: make dev-up
#
# GITHUB CODESPACES:
# 1. Repository secrets are automatically injected into the environment
# 2. No manual .env editing required - secrets override .env values
# 3. Start development: make dev-up
#
# SECURITY NOTES:
# - Repository secrets are encrypted and only available in GitHub environment
# - Local .env files are ignored by git (not committed to repository)
# - For production, use secure secret management systems
#
# REQUIRED FOR RAG FUNCTIONALITY:
# - WatsonX API credentials (WATSONX_APIKEY, WATSONX_INSTANCE_ID)
# - IBM OIDC credentials (IBM_CLIENT_ID, IBM_CLIENT_SECRET)
# - Without these, RAG features (search, embeddings) will not work

# =============================================================================
# PODCAST GENERATION SETTINGS (Issue #240)
# =============================================================================

# Podcast Environment: development or production
# - development: FastAPI BackgroundTasks + local filesystem storage
# - production: Celery + Redis + MinIO/S3 storage
PODCAST_ENVIRONMENT=development

# Task Backend (set automatically based on PODCAST_ENVIRONMENT)
# Options: fastapi, celery
PODCAST_TASK_BACKEND=fastapi

# Storage Backend (set automatically based on PODCAST_ENVIRONMENT)
# Options: local, minio, s3, r2
PODCAST_STORAGE_BACKEND=local

# Local Filesystem Storage (Development only)
PODCAST_LOCAL_STORAGE_PATH=./data/podcasts

# MinIO/S3 Storage (Production only - optional in development)
# PODCAST_MINIO_ENDPOINT=http://minio:9000
# PODCAST_MINIO_ACCESS_KEY=your-minio-access-key
# PODCAST_MINIO_SECRET_KEY=your-minio-secret-key
# PODCAST_MINIO_BUCKET=rag-modulo-podcasts

# Celery Configuration (Production only)
# CELERY_BROKER_URL=redis://localhost:6379/0
# CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Audio Generation Provider
# Options: openai, watsonx
PODCAST_AUDIO_PROVIDER=openai

# OpenAI TTS Configuration (if using openai provider)
# OPENAI_API_KEY is already configured above
OPENAI_TTS_MODEL=tts-1-hd
OPENAI_TTS_DEFAULT_VOICE=alloy

# WatsonX TTS Configuration (if using watsonx provider or as fallback)
# WATSONX_TTS_API_KEY=your-watsonx-tts-api-key
# WATSONX_TTS_URL=https://api.us-south.text-to-speech.watson.cloud.ibm.com
# WATSONX_TTS_DEFAULT_VOICE=en-US_AllisonV3Voice
# PODCAST_FALLBACK_AUDIO_PROVIDER=watsonx

# Podcast Validation & Limits
PODCAST_MIN_DOCUMENTS=5
PODCAST_MAX_CONCURRENT_PER_USER=3
PODCAST_URL_EXPIRY_DAYS=7

# Content Retrieval Settings (top_k by duration)
PODCAST_RETRIEVAL_TOP_K_SHORT=30     # 5 minutes
PODCAST_RETRIEVAL_TOP_K_MEDIUM=50    # 15 minutes
PODCAST_RETRIEVAL_TOP_K_LONG=75      # 30 minutes
PODCAST_RETRIEVAL_TOP_K_EXTENDED=100 # 60 minutes
