services:
  # Main database used for persistence by backend and some infra components
  postgres:
    ports:
      - "5432:5432"
    image: postgres:13
    networks:
      - app-network
    environment:
      POSTGRES_DB: ${COLLECTIONDB_NAME}
      POSTGRES_USER: ${COLLECTIONDB_USER}
      POSTGRES_PASSWORD: ${COLLECTIONDB_PASS}
      COLLECTIONDB_NAME: ${COLLECTIONDB_NAME}
      COLLECTIONDB_USER: ${COLLECTIONDB_USER}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${COLLECTIONDB_USER} -d ${COLLECTIONDB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # AWS S3 compatible storage services used by Milvus and MLFlow
  minio:
    ports:
      - "9001:9001"
    container_name: minio
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    command: minio server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  # etcd for milvus standalone deployment
  milvus-etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.9
    environment:
      - ETCD_NAME=etcd
      - ETCD_DATA_DIR=/etcd-data
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://milvus-etcd:2379
      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://milvus-etcd:2380
      - ETCD_INITIAL_CLUSTER=etcd=http://milvus-etcd:2380
      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster
      - ETCD_INITIAL_CLUSTER_STATE=new
    volumes:
      - etcd_data:/etcd-data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "etcdctl", "--endpoints=http://localhost:2379", "endpoint", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  milvus-standalone:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.4.4
    command: ["milvus", "run", "standalone"]
    ports:
      - "19530:19530"
    environment:
      ETCD_ENDPOINTS: milvus-etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      COMMON_STORAGETYPE: minio
      MINIO_USE_SSL: false
      ETCD_USE_SSL: false
    volumes:
      - milvus_data:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    depends_on:
      milvus-etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    networks:
      - app-network

  # Create minio bucket for MLFlow
  createbuckets:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://minio:9000 $$MINIO_ROOT_USER $$MINIO_ROOT_PASSWORD;
      /usr/bin/mc mb --ignore-existing myminio/rag-modulo-mlflow;
      exit 0;
      "
    networks:
      - app-network

  mlflow-server:
    ports:
      - "5001:5000"
    image: quay.io/mtykhenko/rag-modulo-mlflow:latest
    environment:
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_ARTIFACT_URI: s3://rag-modulo-mlflow
      MLFLOW_BACKEND_STORE_URI: "postgresql+psycopg2://${COLLECTIONDB_USER}:${COLLECTIONDB_PASS}@postgres:5432/${COLLECTIONDB_NAME}"
      MLFLOW_TRACKING_USERNAME: ${MLFLOW_TRACKING_USERNAME:-mlflow}
      MLFLOW_TRACKING_PASSWORD: ${MLFLOW_TRACKING_PASSWORD:-mlflow123}
    # Health check disabled - MLflow container doesn't have curl/wget
    # Service is accessible at http://localhost:5001/health from host
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
      createbuckets:
        condition: service_completed_successfully
    networks:
      - app-network

  # ============================================================================
  # MCP Context Forge Services (Optional - only started with --profile mcp)
  # ============================================================================
  # To enable: Set ENABLE_MCP_GATEWAY=true in your .env file
  # The Makefile will automatically pass --profile mcp to docker-compose
  # ============================================================================

  # Redis for MCP Context Forge gateway caching and session management
  redis:
    container_name: redis
    image: redis:7-alpine
    profiles:
      - mcp
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    networks:
      - app-network

  # MCP Context Forge Gateway - Model Context Protocol server
  # Provides tool discovery and invocation capabilities for RAG enrichment
  # Port 3001 by default to avoid conflict with frontend (port 3000)
  #
  # AUTHENTICATION ARCHITECTURE:
  # RAG Modulo uses PROXY AUTHENTICATION - it acts as a trusted backend service
  # that passes authenticated user identity via headers. No JWT token exchange needed.
  # See: https://ibm.github.io/mcp-context-forge/manage/proxy/
  #
  # IMAGE VERSION: Pinned to SHA digest for reproducibility (updated 2025-12-01)
  # To update: docker pull ghcr.io/ibm/mcp-context-forge:latest && docker inspect --format='{{index .RepoDigests 0}}'
  mcp-context-forge:
    container_name: mcp-context-forge
    image: ghcr.io/ibm/mcp-context-forge@sha256:654c72fd4d2ed3ce0716214e6adf517fbba3ef105f39864a0deb326f90475797
    profiles:
      - mcp
    ports:
      - "${MCP_PORT:-3001}:${MCP_PORT:-3001}"
    environment:
      # Server port (MCP Context Forge uses PORT env var)
      PORT: ${MCP_PORT:-3001}
      HOST: 0.0.0.0
      # Redis configuration for caching
      REDIS_URL: redis://redis:6379
      # ========================================
      # PROXY AUTHENTICATION (Recommended)
      # ========================================
      # RAG Modulo is a TRUSTED BACKEND SERVICE, not an end-user client.
      # With proxy auth, RAG Modulo passes the authenticated user's identity
      # via a header, and MCP trusts it without requiring JWT token exchange.
      TRUST_PROXY_AUTH: ${MCP_TRUST_PROXY_AUTH:-true}
      PROXY_USER_HEADER: ${MCP_PROXY_USER_HEADER:-X-Authenticated-User}
      # Disable client-side JWT auth when using proxy auth
      MCP_CLIENT_AUTH_ENABLED: ${MCP_CLIENT_AUTH_ENABLED:-false}
      # ========================================
      # ADMIN UI AUTHENTICATION
      # ========================================
      # AUTH_REQUIRED controls the admin web UI, not API calls
      AUTH_REQUIRED: ${MCP_AUTH_REQUIRED:-false}
      # Admin credentials for web UI (only needed if AUTH_REQUIRED=true)
      PLATFORM_ADMIN_EMAIL: ${MCP_ADMIN_EMAIL:-admin@example.com}
      PLATFORM_ADMIN_PASSWORD: ${MCP_ADMIN_PASSWORD:-change-me-in-production}
      # JWT secret for admin UI tokens (not used for proxy auth)
      JWT_SECRET_KEY: ${MCP_JWT_SECRET:-dev-jwt-secret-change-in-production}
      # Logging
      LOG_LEVEL: ${MCP_LOG_LEVEL:-info}
    volumes:
      - mcp_tools:/app/tools
    healthcheck:
      # Use wget instead of curl (Alpine-based image)
      # Note: Health check uses internal PORT env var set above
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:$${PORT}/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network

volumes:
  postgres_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/postgres
      o: bind
  etcd_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/etcd
      o: bind
  minio_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/minio
      o: bind
  milvus_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/milvus
      o: bind
  redis_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/redis
      o: bind
  mcp_tools:
    driver_opts:
      type: none
      device: ${PWD}/volumes/mcp_tools
      o: bind

networks:
  app-network:
    driver: bridge
