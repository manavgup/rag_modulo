services:
  # Main database used for persistence by backend and some infra components
  postgres:
    ports:
      - "5432:5432"
    image: postgres:13
    networks:
      - app-network
    environment:
      POSTGRES_DB: ${COLLECTIONDB_NAME}
      POSTGRES_USER: ${COLLECTIONDB_USER}
      POSTGRES_PASSWORD: ${COLLECTIONDB_PASS}
      COLLECTIONDB_NAME: ${COLLECTIONDB_NAME}
      COLLECTIONDB_USER: ${COLLECTIONDB_USER}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${COLLECTIONDB_USER} -d ${COLLECTIONDB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # AWS S3 compatible storage services used by Milvus and MLFlow
  minio:
    ports:
      - "9001:9001"
    container_name: minio
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    command: minio server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  # etcd for milvus standalone deployment
  milvus-etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.9
    environment:
      - ETCD_NAME=etcd
      - ETCD_DATA_DIR=/etcd-data
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://milvus-etcd:2379
      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://milvus-etcd:2380
      - ETCD_INITIAL_CLUSTER=etcd=http://milvus-etcd:2380
      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster
      - ETCD_INITIAL_CLUSTER_STATE=new
    volumes:
      - etcd_data:/etcd-data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "etcdctl", "--endpoints=http://localhost:2379", "endpoint", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  milvus-standalone:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.4.4
    command: ["milvus", "run", "standalone"]
    ports:
      - "19530:19530"
    environment:
      ETCD_ENDPOINTS: milvus-etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      COMMON_STORAGETYPE: minio
      MINIO_USE_SSL: false
      ETCD_USE_SSL: false
    volumes:
      - milvus_data:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    depends_on:
      milvus-etcd:
        condition: service_healthy
      minio:
        condition: service_healthy
    networks:
      - app-network

  # Create minio bucket for MLFlow
  createbuckets:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://minio:9000 $$MINIO_ROOT_USER $$MINIO_ROOT_PASSWORD;
      /usr/bin/mc mb --ignore-existing myminio/rag-modulo-mlflow;
      exit 0;
      "
    networks:
      - app-network

  mlflow-server:
    ports:
      - "5001:5000"
    image: quay.io/mtykhenko/rag-modulo-mlflow:latest
    environment:
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_ARTIFACT_URI: s3://rag-modulo-mlflow
      MLFLOW_BACKEND_STORE_URI: "postgresql+psycopg2://${COLLECTIONDB_USER}:${COLLECTIONDB_PASS}@postgres:5432/${COLLECTIONDB_NAME}"
      MLFLOW_TRACKING_USERNAME: ${MLFLOW_TRACKING_USERNAME:-mlflow}
      MLFLOW_TRACKING_PASSWORD: ${MLFLOW_TRACKING_PASSWORD:-mlflow123}
    # Health check disabled - MLflow container doesn't have curl/wget
    # Service is accessible at http://localhost:5001/health from host
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
      createbuckets:
        condition: service_completed_successfully
    networks:
      - app-network

  # Redis for MCP Context Forge gateway caching and session management
  redis:
    container_name: redis
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    networks:
      - app-network

  # MCP Context Forge Gateway - Model Context Protocol server
  # Provides tool discovery and invocation capabilities for RAG enrichment
  # Note: Uses port 3001 to avoid conflict with frontend (port 3000)
  mcp-context-forge:
    container_name: mcp-context-forge
    image: ghcr.io/ibm/mcp-context-forge:latest
    ports:
      - "3001:3001"
    environment:
      # Server configuration (port 3001 to avoid frontend conflict)
      MCP_SERVER_PORT: 3001
      MCP_SERVER_HOST: 0.0.0.0
      # Redis configuration for caching
      REDIS_URL: redis://redis:6379
      # JWT authentication (optional - set MCP_JWT_SECRET to enable)
      MCP_JWT_SECRET: ${MCP_JWT_SECRET:-}
      # Logging
      LOG_LEVEL: ${MCP_LOG_LEVEL:-info}
      # Tool registry
      MCP_TOOLS_DIR: /app/tools
    volumes:
      - mcp_tools:/app/tools
    healthcheck:
      # Use wget instead of curl (Alpine-based image)
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - app-network

volumes:
  postgres_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/postgres
      o: bind
  etcd_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/etcd
      o: bind
  minio_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/minio
      o: bind
  milvus_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/milvus
      o: bind
  redis_data:
    driver_opts:
      type: none
      device: ${PWD}/volumes/redis
      o: bind
  mcp_tools:
    driver_opts:
      type: none
      device: ${PWD}/volumes/mcp_tools
      o: bind

networks:
  app-network:
    driver: bridge
